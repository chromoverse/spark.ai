"""
SQH Service
Handles Secondary Query Handler logic:
1. Generates Task Plan using LLM
2. Registers tasks with Orchestrator
3. Triggers Execution Engine

‚úÖ UPDATED: Returns execution task for proper awaiting
"""

import logging
import json
import asyncio
from typing import List, Dict, Any

from app.core.models import LifecycleMessages, Task
from app.models.pqh_response_model import PQHResponse
from app.prompts.sqh_prompt import build_sqh_prompt
from app.ai.providers import llm_chat
from app.core.orchestrator import get_orchestrator
from app.core.execution_engine import get_execution_engine
from app.core.server_executor import get_server_executor
from app.core.task_emitter import get_task_emitter

logger = logging.getLogger(__name__)

async def process_sqh(
    pqh_response: PQHResponse,
    user_details: Dict[str, Any]
) -> None:
    """
    Process SQH in background - AUTO INITIALIZES and STARTS EXECUTION:
    - Generate Plan
    - Register Tasks
    - Trigger Execution Engine (automatically, no waiting)
    
    ‚úÖ UPDATED: Auto-starts execution, no need for caller to manage
    
    Returns:
        None: Fire-and-forget, execution runs in background
    
    Raises:
        ValueError: If LLM response is invalid or parsing fails
        RuntimeError: If task generation fails
    
    Example:
        # Just call and forget - execution starts automatically
        await process_sqh(pqh_response, user_details)
    """
    user_id = user_details.get("_id", "guest")
    # user_details['id'] might be ObjectId, ensure string
    if not isinstance(user_id, str):
        user_id = str(user_id)

    logger.info(f"üöÄ [SQH] Starting background task generation for user: {user_id}")

    try:
        # 1. Build Prompt
        prompt = build_sqh_prompt(pqh_response, user_details)
        
        # 2. Call AI via unified provider system (auto fallback: Groq ‚Üí Gemini ‚Üí OpenRouter)
        messages = [{"role": "user", "content": prompt}]
        
        logger.info("üß† [SQH] calling LLM...")
        raw_response, provider = await llm_chat(messages=messages)
        
        logger.info(f"‚úÖ [SQH] Response {raw_response} received from {provider}")

        # ‚úÖ FIX: Raise instead of return
        if not raw_response:
            error_msg = "Empty response from LLM"
            logger.error(f"‚ùå [SQH] {error_msg}")
            raise ValueError(error_msg)
        
        # 3. Parse Response
        try:
            # Clean markdown code blocks if present
            cleaned_json = raw_response.strip()
            if cleaned_json.startswith("```json"):
                cleaned_json = cleaned_json.split("\n", 1)[1]
            if cleaned_json.endswith("```"):
                cleaned_json = cleaned_json.rsplit("\n", 1)[0]
            
            data = json.loads(cleaned_json)
            
            # Handle both {"tasks": [...]} and [...] formats
            if isinstance(data, list):
                tasks_data = data
            elif isinstance(data, dict):
                tasks_data = data.get("tasks", [])
            else:
                # ‚úÖ FIX: Raise instead of return
                error_msg = f"Invalid JSON format: {type(data)}"
                logger.error(f"‚ùå [SQH] {error_msg}")
                raise ValueError(error_msg)
            
            logger.info(f"SQH response:\n{json.dumps(tasks_data, indent=2)}")
            # Parse into Task objects
            tasks = [Task(**task_data) for task_data in tasks_data]
            
            # ‚úÖ FIX: Raise instead of return
            if not tasks:
                error_msg = "No tasks generated by LLM"
                logger.warning(f"‚ö†Ô∏è [SQH] {error_msg}")
                raise ValueError(error_msg)
            
            logger.info(f"üìã [SQH] Parsed {len(tasks)} tasks:")
            for task in tasks:
                logger.info(f"   - {task.task_id}: {task.tool} ({task.execution_target})")

        except json.JSONDecodeError as e:
            # ‚úÖ FIX: Raise instead of return
            error_msg = f"JSON Parse Error: {e}"
            logger.error(f"‚ùå [SQH] {error_msg}")
            logger.debug(f"Raw response: {raw_response}")
            raise ValueError(error_msg) from e
        except ValueError:
            # Re-raise ValueError from above
            raise
        except Exception as e:
            # ‚úÖ FIX: Raise instead of return
            error_msg = f"Task Validation Error: {e}"
            logger.error(f"‚ùå [SQH] {error_msg}")
            raise RuntimeError(error_msg) from e

        # 4. Register Tasks
        logger.info(f"üìù [SQH] Registering {len(tasks)} tasks with Orchestrator...")
        orchestrator = get_orchestrator()
        await orchestrator.register_tasks(user_id, tasks)
        
        # 5. Setup Execution Dependencies
        execution_engine = get_execution_engine()
        
        # ‚úÖ Ensure server executor is set
        if not execution_engine.server_tool_executor:
            logger.info("üîß [SQH] Injecting server executor...")
            execution_engine.set_server_executor(get_server_executor())
        
        # ‚úÖ Ensure client emitter is set AND configured
        if not execution_engine.client_task_emitter:
            logger.info("üîß [SQH] Setting up client task emitter...")
            # This initializes emitter AND wires callback to client_core
            client_emitter = get_task_emitter()
            execution_engine.set_client_emitter(client_emitter)
        
        # 6. Trigger Execution Engine - AUTO START (fire-and-forget)
        logger.info(f"‚ö° [SQH] Starting execution for {len(tasks)} tasks...")
        await execution_engine.start_execution(user_id)
        
        logger.info(f"‚úÖ [SQH] Execution workflow auto-started for user: {user_id}")
        
        # ‚úÖ No need to return - execution runs in background automatically
        return None

    except Exception as e:
        logger.error(f"‚ùå [SQH] Critical Failure: {e}", exc_info=True)
        raise