# ğŸ¤– Hybrid Python + Electron Automation Architecture

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Electron Frontend                         â”‚
â”‚  â€¢ Voice/Text Input                                          â”‚
â”‚  â€¢ Display Results                                           â”‚
â”‚  â€¢ Simple System Tasks (open apps, URLs)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ Socket.IO
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Python Backend (AI + Context)                   â”‚
â”‚  â€¢ OpenRouter AI                                             â”‚
â”‚  â€¢ Context Management (Redis/Pinecone)                       â”‚
â”‚  â€¢ Speech-to-Text                                            â”‚
â”‚  â€¢ Decision Making                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ HTTP/Socket.IO
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Python Automation Service (Separate Process)         â”‚
â”‚  â€¢ PyAutoGUI - Mouse/Keyboard control                        â”‚
â”‚  â€¢ Pyperclip - Clipboard operations                          â”‚
â”‚  â€¢ Selenium - Browser automation                             â”‚
â”‚  â€¢ OpenCV - Computer vision                                  â”‚
â”‚  â€¢ Pillow - Screenshot/Image processing                      â”‚
â”‚  â€¢ psutil - System monitoring                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Required Python Libraries

```bash
# Automation Libraries
pip install pyautogui          # Mouse/keyboard automation
pip install pyperclip          # Clipboard operations
pip install pillow             # Screenshots, image processing
pip install opencv-python      # Computer vision
pip install pytesseract        # OCR (reading text from screen)
pip install selenium           # Browser automation
pip install webdriver-manager  # Auto-download browser drivers
pip install psutil             # System/process management
pip install pygetwindow        # Window management
pip install keyboard           # Advanced keyboard control
pip install mouse              # Advanced mouse control

# Windows-specific (optional)
pip install pywin32            # Windows API access
pip install pywinauto          # Windows GUI automation

# Cross-platform alternatives
pip install pynput             # Cross-platform input control
```

---

## ğŸ—ï¸ Implementation Strategy

### **Option 1: Microservices (Recommended) â­**

Run Python automation as a **separate service** that both Electron and Python backend can call.

```
Python Backend (AI)  â†â”€â”
                       â”œâ”€â”€â†’  Python Automation Service
Electron Frontend   â†â”€â”˜
```

**Benefits:**
- âœ… Isolated automation logic
- âœ… Can restart automation without affecting AI
- âœ… Better error handling
- âœ… Scalable

### **Option 2: Unified Backend**

Include automation directly in your Python backend.

```
Python Backend (AI + Automation) â†â”€â”€ Electron Frontend
```

**Benefits:**
- âœ… Simpler architecture
- âœ… Easier deployment
- âœ… Single codebase

---

## ğŸ¯ What Each Layer Does

### **Electron (Simple System Tasks)**
```javascript
// Only for simple, native OS operations
- Open apps (calculator, notepad, etc.)
- Open URLs in browser
- File system operations (read/write files)
- System notifications
- Tray icon management
```

### **Python Automation Service (Complex Tasks)**
```python
# For automation requiring precise control
- Click specific coordinates/elements
- Fill forms automatically
- Take screenshots
- Read text from screen (OCR)
- Move/resize windows
- Type in any application
- Browser automation (Selenium)
- Image recognition (OpenCV)
```

---

## ğŸ’» Code Implementation

### **1. Python Automation Service**

```python
# automation_service.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import pyautogui
import pyperclip
from PIL import ImageGrab
import cv2
import numpy as np
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
import logging

app = FastAPI()
logger = logging.getLogger(__name__)

# Configure PyAutoGUI
pyautogui.FAILSAFE = True  # Move mouse to corner to abort
pyautogui.PAUSE = 0.5  # Pause between actions

class ClickAction(BaseModel):
    x: int
    y: int
    clicks: int = 1
    button: str = "left"

class TypeAction(BaseModel):
    text: str
    interval: float = 0.0

class SearchAndClickAction(BaseModel):
    image_path: str  # Path to image to find
    confidence: float = 0.8

class FillFormAction(BaseModel):
    fields: dict  # {"field_name": "value"}
    url: str

@app.post("/click")
async def click_at_position(action: ClickAction):
    """Click at specific screen coordinates"""
    try:
        pyautogui.click(
            x=action.x, 
            y=action.y, 
            clicks=action.clicks, 
            button=action.button
        )
        return {"success": True, "message": f"Clicked at ({action.x}, {action.y})"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/type")
async def type_text(action: TypeAction):
    """Type text with optional interval"""
    try:
        pyautogui.write(action.text, interval=action.interval)
        return {"success": True, "message": f"Typed: {action.text}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/hotkey")
async def press_hotkey(keys: list[str]):
    """Press keyboard shortcut (e.g., ['ctrl', 'c'])"""
    try:
        pyautogui.hotkey(*keys)
        return {"success": True, "message": f"Pressed: {'+'.join(keys)}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/screenshot")
async def take_screenshot(save_path: str = None):
    """Take screenshot and optionally save"""
    try:
        screenshot = pyautogui.screenshot()
        
        if save_path:
            screenshot.save(save_path)
            return {"success": True, "path": save_path}
        
        # Convert to base64 for return
        import base64
        from io import BytesIO
        
        buffered = BytesIO()
        screenshot.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        
        return {"success": True, "image": img_str}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/find-and-click")
async def find_and_click_image(action: SearchAndClickAction):
    """Find image on screen and click it"""
    try:
        location = pyautogui.locateOnScreen(
            action.image_path, 
            confidence=action.confidence
        )
        
        if location:
            center = pyautogui.center(location)
            pyautogui.click(center)
            return {
                "success": True, 
                "message": f"Found and clicked at {center}",
                "location": location
            }
        else:
            return {
                "success": False, 
                "message": "Image not found on screen"
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/mouse-position")
async def get_mouse_position():
    """Get current mouse position"""
    x, y = pyautogui.position()
    return {"x": x, "y": y}

@app.post("/move-mouse")
async def move_mouse(x: int, y: int, duration: float = 0.5):
    """Move mouse to position with animation"""
    try:
        pyautogui.moveTo(x, y, duration=duration)
        return {"success": True, "position": {"x": x, "y": y}}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/copy-to-clipboard")
async def copy_to_clipboard(text: str):
    """Copy text to clipboard"""
    try:
        pyperclip.copy(text)
        return {"success": True, "message": "Copied to clipboard"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/paste-from-clipboard")
async def paste_from_clipboard():
    """Get text from clipboard"""
    try:
        text = pyperclip.paste()
        return {"success": True, "text": text}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/fill-form")
async def fill_form_with_selenium(action: FillFormAction):
    """Fill web form using Selenium"""
    try:
        driver = webdriver.Chrome()
        driver.get(action.url)
        time.sleep(2)
        
        for field_name, value in action.fields.items():
            element = driver.find_element(By.NAME, field_name)
            element.clear()
            element.send_keys(value)
            time.sleep(0.5)
        
        driver.quit()
        return {"success": True, "message": "Form filled successfully"}
    except Exception as e:
        if 'driver' in locals():
            driver.quit()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/screen-text")
async def read_screen_text(x: int = 0, y: int = 0, width: int = None, height: int = None):
    """Extract text from screen region using OCR"""
    try:
        import pytesseract
        
        # Take screenshot of region
        if width and height:
            screenshot = ImageGrab.grab(bbox=(x, y, x+width, y+height))
        else:
            screenshot = ImageGrab.grab()
        
        # Extract text
        text = pytesseract.image_to_string(screenshot)
        
        return {"success": True, "text": text}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "automation"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### **2. Update Main Chat Service to Call Automation**

```python
# app/services/chat_service.py
import httpx

AUTOMATION_SERVICE_URL = "http://localhost:8000"

async def execute_automation_action(action_details):
    """Call automation service for complex tasks"""
    
    action_type = action_details.get("type")
    
    async with httpx.AsyncClient() as client:
        try:
            if action_type == "click_button":
                # Click at specific coordinates
                response = await client.post(
                    f"{AUTOMATION_SERVICE_URL}/click",
                    json={
                        "x": action_details["x"],
                        "y": action_details["y"]
                    }
                )
                
            elif action_type == "type_text":
                # Type text anywhere
                response = await client.post(
                    f"{AUTOMATION_SERVICE_URL}/type",
                    json={"text": action_details["text"]}
                )
                
            elif action_type == "fill_form":
                # Fill web form
                response = await client.post(
                    f"{AUTOMATION_SERVICE_URL}/fill-form",
                    json={
                        "url": action_details["url"],
                        "fields": action_details["fields"]
                    }
                )
                
            elif action_type == "take_screenshot":
                # Take screenshot
                response = await client.get(
                    f"{AUTOMATION_SERVICE_URL}/screenshot"
                )
                
            elif action_type == "find_and_click":
                # Find image and click
                response = await client.post(
                    f"{AUTOMATION_SERVICE_URL}/find-and-click",
                    json={
                        "image_path": action_details["image_path"],
                        "confidence": 0.8
                    }
                )
            
            return response.json()
            
        except Exception as e:
            logger.error(f"Automation service error: {e}")
            return {"success": False, "error": str(e)}
```

### **3. Action Dispatcher with Automation Support**

```python
# app/services/actions/action_dispatcher.py

from app.features.app_features.open_app import open_app
from app.features.automation_features.automation_actions import (
    click_at_position,
    type_text_anywhere,
    fill_web_form,
    take_screenshot,
    copy_paste_text,
    find_and_click_image
)

ACTION_MAP = {
    # Simple actions (handled locally)
    "open_app": open_app,
    "search": search_web,
    "play_song": play_song,
    
    # Complex automation (requires automation service)
    "click_button": click_at_position,
    "type_text": type_text_anywhere,
    "fill_form": fill_web_form,
    "take_screenshot": take_screenshot,
    "copy_paste": copy_paste_text,
    "find_and_click": find_and_click_image,
}

async def dispatch_action(action_type, details):
    """Route action to appropriate handler"""
    handler = ACTION_MAP.get(action_type)
    
    if handler:
        result = await handler(details)
        return result
    else:
        return {"success": False, "error": f"Unknown action: {action_type}"}
```

---

## ğŸ¯ Example Use Cases

### **1. Fill Google Form**

**User:** "Fill the Google form with my details"

**AI Response:**
```json
{
  "action": "fill_form",
  "actionDetails": {
    "type": "fill_form",
    "url": "https://forms.google.com/...",
    "fields": {
      "name": "Siddhant",
      "email": "siddhant@example.com",
      "age": "19"
    }
  }
}
```

**Automation Service:** Opens browser, fills form automatically

---

### **2. Click 'Submit' Button**

**User:** "Click the submit button"

**AI Response:**
```json
{
  "action": "find_and_click",
  "actionDetails": {
    "type": "find_and_click",
    "image_path": "submit_button.png"
  }
}
```

**Automation Service:** Finds button image on screen and clicks it

---

### **3. Take Screenshot and Analyze**

**User:** "Take a screenshot and tell me what's on screen"

**AI Response:**
```json
{
  "action": "take_screenshot",
  "actionDetails": {
    "type": "take_screenshot"
  }
}
```

**Automation Service:** 
1. Takes screenshot
2. Uses OCR to extract text
3. Sends to AI for analysis
4. AI provides insights

---

### **4. Copy Text and Paste**

**User:** "Copy this code and paste it in VS Code"

**Automation Service:**
```python
# 1. Copy to clipboard
pyperclip.copy(code_content)

# 2. Find VS Code window
pyautogui.getWindowsWithTitle("Visual Studio Code")[0].activate()

# 3. Paste
pyautogui.hotkey('ctrl', 'v')
```

---

## ğŸš€ Complete System Setup

### **Terminal 1: Main Python Backend (AI)**
```bash
cd python-backend
uvicorn app.main:app --host 0.0.0.0 --port 5000 --reload
```

### **Terminal 2: Automation Service**
```bash
cd python-backend
uvicorn automation_service:app --host 0.0.0.0 --port 8000 --reload
```

### **Terminal 3: Electron App**
```bash
npm start
```

---

## âš¡ Performance Considerations

### **PyAutoGUI Limitations**
- âŒ Not thread-safe (use single process)
- âŒ Slow for rapid actions
- âŒ Resolution-dependent (coordinates change with screen size)

### **Solutions**
```python
# 1. Use relative positioning
screen_width, screen_height = pyautogui.size()
center_x = screen_width // 2
center_y = screen_height // 2

# 2. Use image recognition instead of coordinates
button_location = pyautogui.locateOnScreen('button.png')

# 3. Add failsafes
pyautogui.FAILSAFE = True  # Move to corner to abort
pyautogui.PAUSE = 0.5  # Delay between actions
```

---

## ğŸ¨ Advanced Features

### **Computer Vision (OpenCV)**

```python
import cv2
import numpy as np

def find_element_by_color(color_range):
    """Find UI elements by color"""
    screenshot = np.array(ImageGrab.grab())
    hsv = cv2.cvtColor(screenshot, cv2.COLOR_BGR2HSV)
    
    # Define color range
    lower = np.array(color_range[0])
    upper = np.array(color_range[1])
    
    # Find matching pixels
    mask = cv2.inRange(hsv, lower, upper)
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    return contours
```

### **Window Management**

```python
import pygetwindow as gw

def focus_window(title):
    """Bring window to front"""
    windows = gw.getWindowsWithTitle(title)
    if windows:
        windows[0].activate()
        return True
    return False

def resize_window(title, width, height):
    """Resize application window"""
    windows = gw.getWindowsWithTitle(title)
    if windows:
        windows[0].resizeTo(width, height)
```

---

## âœ… Recommendation

**Use this hybrid approach:**

1. **Electron** â†’ Simple system tasks (open apps, URLs)
2. **Python Automation Service** â†’ Complex automation (clicks, typing, forms)
3. **Main Python Backend** â†’ AI logic, context, decision-making

This gives you the **best of both worlds**:
- âœ… Beautiful native UI (Electron)
- âœ… Powerful automation (Python)
- âœ… Smart AI decisions (OpenRouter)
- âœ… Clean architecture
- âœ… Easy to maintain
